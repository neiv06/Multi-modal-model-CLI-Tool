# Multi-modal CLI tool
With multi-modal models CLIP and open_clip, I implemented a zero-shot image classification program in Python that outputs image-text similarity scores. The command line tool reads text prompts from the command line and outputs matching scores for each image in a local directory, along with displaying four images with the highest similarity scores to the prompt. 
