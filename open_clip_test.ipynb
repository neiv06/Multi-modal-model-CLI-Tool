{"cells":[{"cell_type":"code","execution_count":null,"id":"e9f263da-a15b-48f9-8452-936838b6a32a","metadata":{"id":"e9f263da-a15b-48f9-8452-936838b6a32a"},"outputs":[],"source":["import open_clip\n","\n","model, preprocess = open_clip.create_model_from_pretrained('hf-hub:laion/CLIP-ViT-g-14-laion2B-s12B-b42K')\n","tokenizer = open_clip.get_tokenizer('hf-hub:laion/CLIP-ViT-g-14-laion2B-s12B-b42K')"]},{"cell_type":"code","execution_count":null,"id":"d0663a3a-177d-400e-a380-471f6df59c3c","metadata":{"id":"d0663a3a-177d-400e-a380-471f6df59c3c","outputId":"959f9932-760e-4a35-cbf4-856d7a2db7af"},"outputs":[{"name":"stdout","output_type":"stream","text":["Label probs: tensor([[1.]])\n"]}],"source":["import torch\n","from PIL import Image\n","import requests\n","import matplotlib as plt\n","\n","url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n","image = Image.open(requests.get(url, stream=True).raw)\n","image = preprocess(image).unsqueeze(0)\n","text = tokenizer([\"a dog\", \"a cat\", \"a couch\"])\n","\n","with torch.no_grad(), torch.cuda.amp.autocast():\n","    image_features = model.encode_image(image)\n","    text_features = model.encode_text(text)\n","    image_features /= image_features.norm(dim=-1, keepdim=True)\n","    text_features /= text_features.norm(dim=-1, keepdim=True)\n","\n","    text_probs = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n","\n","print(\"Label probs:\", text_probs)"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}